sample(1:20,10,replace=FALSE)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips<-sample(c(0,1),100,replace=TRUE,prob=c(.3,.7))
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=.7)
flips2<-replicate(100,rbinom(1,size=100,prob=.7))
flips2<-rbinom(100,size=1,prob=.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100,sd=25)
?rpois
rpois(5,mean=10)
rpois(5,lambda=10)
my_pois<-replicate(100,rpois(5,10))
my_pois
colMeans(my_pois)
cm<-colMeans(my_pois)
hist(cm)
swirl()
mat.data
mat.data<-1:10
str(mat.data)
?set
str(set)
set.seed(1)
rpois(5,2)
?rpois
rpois(5,2)
rpois(5,2)
set.seed(1)
rpois(5,2)
set.seed()
?set.seed()
?rep
str(rep)
rep(1:5,each=5)
set.seed(10)
x<-rep(0:1,each=5)
e<-rnorm(10,0,20)
y<-.5+2*x+e
plot(x,y)
set.seed(1)
rpois(5,2)
library()
install.packages()
install.packages(.library)
install.packages(.Library)
install.packages("quantmod")
install.packages("qmao")
library(quantmod)
getSymbols("GS")
str(GS)
tail(GS)
library(swirl)
swirl
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv,stringAsFactors=FALSE)
?read.csv
mydf<-read.csv(path2csv,stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tbl_df(mydf)
rm("mydf")
cran
?select
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
select(cran,-5:20)
-5:20
-(5:20)
select(cran,-(X:size))
fliter(cran,package=="swirl")
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version=="3.0.2",country=="IN")
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500,r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",method = "curl")
getwd
getwd()
ls
ls()
dir()
?file.create
file.create(data)
file.create("data")
dir()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile = "data/GetDataQ1-1.csv",method = "curl")
dir()
read.csv("data/GetDataQ1-1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile = "data\GetDataQ1-1.csv",method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile = "data/GetDataQ1-1.csv",method = "curl")
data1<-read.csv("data/GetDataQ1-1.csv")
head(data1)
data1$VAL=24
sum(data1$VAL==24)
data1$VAL==24
data1$VAL
data1<-read.csv("data/GetDataQ1-1.csv")
sum(data1$VAL==24)
data1_val<-data1$VAL[!is.na(data1$VAL)]
sum(data1_val==24)
data1_val
data1$val
data1$VAL
head(data1)
data1$VAL
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile = "data/GetDataQ1-1.csv",method = "curl")
data1<-read.csv("data/GetDataQ1-1.csv")
head(data1)
data1_val<- data1$VAL[!is.na(data1$VAL)]
sum(data1_val==24)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile = "data/GetDataQ1-2.csv",method = "curl")
library(xlsx)
install.packages(xlsx)
install.packages("xlsx")
library(xlsx)
file.remove("data/GetDataQ1-2.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile = "data/GetDataQ1-2.xlsx",method = "curl")
dat<-read.xlsx("data/GetDataQ1-2.xlsx",sheetIndex = 1,colIndex = 7:15,rowIndex = 18:23)
dat
sum(dat$Zip*dat$Ext,na.rm=T)
?with
with(dat,sum(Zip*Ext,na.rm=T))
?sum
library(XML)
install.packages("XML")
library(XML)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl,useInternal=TRUE)
download.file(fileUrl,destfile = "data/GetDataQ1-3.xml",method = "curl")
doc<-xmlTreeParse("data/GetDataQ1-3.xml",useInternal=TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
xmlSApply(rootNode,xmlValue=="zipcode")
xpathSApply(rootNode,"//zipcode",xmlValue)
xmlzip<-as.numeric(xpathSApply(rootNode,"//zipcode",xmlValue))
sum(xmlzip==21231)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,destfile = "data/GetDataQ1-4.csv",method = "curl")
?fread
library(data.table)
install.packages("data.table")
library(data.table)
DT<-fread("data/GetDataQ1-4.csv")
names(DT)
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15)
mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15);
mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(rowMeans(DT)[DT$SEX==2])
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
DT[,mean(pwgtp15),by=SEX]
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(DT[,mean(pwgtp15),by=SEX])
sum(xmlzip==21231)
?mean
?system.time
system.time(for(i in 1:1000) DT[,mean(pwgtp15),by=SEX])
system.time(for(i in 1:1000) tapply(DT$pwgtp15,DT$SEX,mean))
system.time(for(i in 1:1000) sapply(split(DT$pwgtp15,DT$SEX),mean))
165-72
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
?summarize
summarize(by_package,mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count,probs=.99)
top_counts<-filter(by_package,count>679)
?filter
top_counts<-filter(by_package, count > 679)
top_counts<-filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,count)
?arrange
top_counts_sorted<-arrange(top_counts,desc(count)
)
View(top_counts_sorted)
quantile(pack_sum$unique,probs=.99)
top_unique<-filter(pack_sum,unique > 465)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(count))
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
submit()
View(result3)
submit()
submit
submit()
submit()
submit()
submit()
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
student2
students2
res<-gather(students2,sex_class, count,-grade)
res
?separate
separate(res,col=sex_class,into=c("sex","class"))
submit()
students3
submit()
submit()
?spread
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
passed<-mutated(passed,status="passed")
passed<-mutate(passed,status="passed")
failed<-mutate(failed,status="failed")
bind_rows(passed,failed)
sat
?select
submit()
submit()
submit()
submit()
library(httr)
oauth_endpoints("github")
library(sqldf)
install.packages("sqldf")
acs<-read.csv("getdata_q2q2.csv")
type(acs)
head(acs)
sqldf("select * from acs limit 1")
library(sqldf)
?sqldf
sqldf("select * from acs limit 1")
sqldf("select pwgtp1 from acs where AGEP<50")
sqldf("select pwgtp1 from acs where AGEP<50 limit5")
sqldf("select pwgtp1 from acs where AGEP<50 limit 5")
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from acs order by AGEP")
con=url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode=readlines(con)
htmlCode=readLines(con)
close(con)
htmlCode
?nchar
test<-c("a","b","c")
nchar(test)
nchar(test[1,2])
nchar(test[1:2])
nchar(test[[1][2])
nchar(test[[1][2]])
test[c(1,2)]
nchar(htmlCode[(10,20,30,100)])
nchar(htmlCode[c(10,20,30,100)])
htmlCode[30]
library(foregin)
install.packages("foregin")
library(foregin)
install.packages("foreign")
library(foreign)
acs<-read.fwf("getdata_q2q5.for")
?read.fwf
acs<-read.fwf("getdata_q2q5.for",63)
head(acs)
acs<-read.fwf("getdata_q2q5.for",63,skip = 2,header = TRUE)
head(acs)
names(acs)
acs<-read.fwf("getdata_q2q5.for",63,skip = 2,header = TRUE,sep="\t")
names(acs)
head(acs)
acs<-read.fwf("getdata_q2q5.for",63,skip = 2,header = TRUE,sep="")
acs<-read.fwf("getdata_q2q5.for",63,skip = 2,header = TRUE,sep=" ")
acs<-read.fwf("getdata_q2q5.for",63,skip = 3,header = TRUE)
head(acs)
names(acs)
acs<-read.fwf("getdata_q2q5.for",width=c(15,4,9,4,9,4,9,4,4),skip = 3,header = TRUE)
acs<-read.fwf("getdata_q2q5.for",widths=c(12,7,4,9,4,9,4,9,4),skip = 4)
head(acs)
acs<-read.fwf("getdata_q2q5.for",widths=c(12,7,4,9,4,9,4,9,4),skip = 3, header=T)
acs<-read.fwf("getdata_q2q5.for",widths=c(12,7,4,9,4,9,4,9,4),skip = 4)
sum(acs[,4])
myapp<-oauth_app("github", key="8e4ee5a8a31f350a815d",secret="05e1ad9a2032a18f9f6b070cc3fafaa2901574bd")
github_token<-oauth2.0_token(oauth_endpoints("github"),myapp)
github_token<-oauth2.0_token(oauth_endpoints("github"),myapp)
rm(github_token)
github_token<-oauth2.0_token(oauth_endpoints("github"),myapp)
rm(github_token)
rm(myapp)
myapp<-oauth_app("github", key="8e4ee5a8a31f350a815d",secret="05e1ad9a2032a18f9f6b070cc3fafaa2901574bd")
github_token<-oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken<-config(token=github_token)
req<-GET("https://api.github.com/rate_limit",gtoken)
stop_for_status(req)
source("q2q1.R")
github_token<-oauth2.0_token(oauth_endpoints("github"),myapp,cache=FALSE)
getwd()
setwd("/Users/johnho/Desktop/WorkBench/Git/CourseraGetDataProject")
source("run_analysis.R")
?gather
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
head(x_tidy)
count(unique(x_tidy))
count(unique(x_tidy$subject))
unique(x_tidy$subject)
unique(x_tidy$variable_stat)
len(unique(x_tidy$variable_stat))
length(unique(x_tidy$variable_stat))
mutate(x_tidy,stat= unlist(strsplit(as.character(variable_stat),"-"))[2])
mutate(x_tidy,variable=sub(variable_stat,pattern="\\-.+\\-",replacement="-"))
x_tidy<-mutate(x_tidy,variable=sub(variable_stat,pattern="\\-.+\\-",replacement="-")) %>%
select(-variable_stat)
head(x_tidy)
spread(x_tidy,stat,value)
unique(x_tidy$stat)
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
x_tidy
unique(x_tidy$stat)
source("run_analysis.R")
source("run_analysis.R")
head(x_tidy1)
unique(x_tidy1$variable_stat)
x_tidy2<-mutate(x_tidy1,
stat= unlist(strsplit(as.character(variable_stat),"-"))[2])
unique(x_tidy2)
unique(x_tidy2$stat)
x_tidy2<-mutate(x_tidy1,
stat= str_match(variable_stat,"\\-(.+)\\-")[1,2])
library(stringr)
x_tidy2<-mutate(x_tidy1,
stat= str_match(variable_stat,"\\-(.+)\\-")[1,2])
unique(x_tidy2$stat)
x_tidy2<-mutate(x_tidy1,
stat= (str_match(variable_stat,"\\-(.+)\\-")[1,2]))
unique(x_tidy2$stat)
x_tidy2<-mutate(x_tidy1,
stat= str_match(variable_stat,"\\-(.+)\\-"))
x_tidy2<-mutate(x_tidy1,
stat= unlist(strsplit(as.character(variable_stat),"-")))
x_tidy2<-mutate(x_tidy1,
stat= unlist(strsplit(as.character(variable_stat),"-"))[2])
unique(x_tidy2$stat)
?mutate
?mutate_
a<-c("a_mean()_x","b_mean()_x","c_sd()_y")
b<-strsplit(a,"-")[2]
b
b<-strsplit(a,"-")
b
b<-lapply(a, strsplit,"-")
b
b<-strsplit(a,"_")[2]
b
b<-strsplit(a,"_")
b
b<-unlist(strsplit(a,"_"))[2]
b
b<-unlist(strsplit(a,"_"))
b
?split
?lapply
b<-lapply(a,strsplit,"-")
b
b<-lapply(a,strsplit,"_")
b
b<-lapply(strsplit(as.character(a),"\\-"),"[",2)
b
b<-lapply(strsplit(as.character(a),"\\"),"[",2)
b<-lapply(strsplit(as.character(a),"\\_"),"[",2)
b
b<-lapply(unlist(strsplit(as.character(a)),"\\_"),"[",2)
b<-lapply(unlist(strsplit(as.character(a))),"\\_"),"[",2)
b<-lapply(unlist(strsplit(as.character(a),"\\_")),"[",2)
b
source("run_analysis.R")
head(x_tidy)
source("run_analysis.R")
?group_by
head(x_tidy)
source("run_analysis.R")
source("run_analysis.R")
source("run_analysis.R")
head(summary)
head(x_summary)
swirl()
library(swirl)
swirl()
bye()
summarize(x_summary)
?summarize
summarize(x_summary,mean)
swirl()
library(dplyr)
str(x_summary)
bye()
?tbl_df
swirl()
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
bye()
x_summary
summuarize(x_summary,mean(value))
summarize(x_summary,mean(value))
?rename
unique(x_summary$stat)
source("run_analysis.R")
head(x_tidy)
unique(stat)
unique(x_tidy$stat)
spread(x_tidy, stat, value)
?spread
x_tidy[c(9495,9500),]
spread(unique(x_tidy), stat, value)
unique(x_tidy)[c(9180,9298),]
?unique
library(sqldf)
x_split<- sqldf("select * from x_tidy where group by subject,activity,varible_stat")
x_split<- sqldf("select * from x_tidy group by subject,activity,varible_stat")
x_split<- sqldf("select * from x_tidy group by subject,activity,variable_stat")
spread(unique(x_split), stat, value)
source("run_analysis.R")
head(x_tidy)
x_split<-spread(x_tidy,stat,value)
head(x_split)
rename(x_split,"mean()"="mean","std()"="std")
rename(x_split,mean()="mean",std()="std")
?rename
rename(x_split,mean()=mean,std()=std)
rename(x_split,c("mean()"="mean","std()"="std"))
names(x_tidy)[names(x_tidy)=="mean()"]<-"mean"
head(x_tidy)
names(x_split)[names(x_split)=="mean()"]<-"mean"
head(x_split)
source("run_analysis.R")
head(x_tidy)
x_summary<-group_by(x_tidy,variable,activity,subject)
summarize(x_summary,avg_mean=mean(mean))
summarize(x_summary,avg_mean=mean(mean),avg_std=mean(std))
source("run_analysis.R")
view(x_summary)
View(x_summary)
write.table(x_summary,file = "/Users/johnho/Desktop/WorkBench/R/coursera/getdata_project_dataset.txt",row.names = FALSE)
